{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7120a75-3a7c-49b9-9373-bcb3d3159109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13171:MainThread](2021-06-04 00:07:23,511) INFO - qlib.Initialization - [config.py:284] - default_conf: client.\n",
      "[13171:MainThread](2021-06-04 00:07:25,118) INFO - qlib.Initialization - [__init__.py:48] - qlib successfully initialized based on client settings.\n",
      "[13171:MainThread](2021-06-04 00:07:25,120) INFO - qlib.Initialization - [__init__.py:49] - data_path=/Users/harry/.qlib/qlib_data/qlib_cn_1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['KMID', 'KLEN', 'KMID2', 'KUP', 'KUP2', 'KLOW', 'KLOW2', 'KSFT', 'KSFT2', 'OPEN0', 'HIGH0', 'LOW0', 'VWAP0', 'ROC5', 'ROC10', 'ROC20', 'ROC30', 'ROC60', 'MA5', 'MA10', 'MA20', 'MA30', 'MA60', 'STD5', 'STD10', 'STD20', 'STD30', 'STD60', 'BETA5', 'BETA10', 'BETA20', 'BETA30', 'BETA60', 'RSQR5', 'RSQR10', 'RSQR20', 'RSQR30', 'RSQR60', 'RESI5', 'RESI10', 'RESI20', 'RESI30', 'RESI60', 'MAX5', 'MAX10', 'MAX20', 'MAX30', 'MAX60', 'MIN5', 'MIN10', 'MIN20', 'MIN30', 'MIN60', 'QTLU5', 'QTLU10', 'QTLU20', 'QTLU30', 'QTLU60', 'QTLD5', 'QTLD10', 'QTLD20', 'QTLD30', 'QTLD60', 'RANK5', 'RANK10', 'RANK20', 'RANK30', 'RANK60', 'RSV5', 'RSV10', 'RSV20', 'RSV30', 'RSV60', 'IMAX5', 'IMAX10', 'IMAX20', 'IMAX30', 'IMAX60', 'IMIN5', 'IMIN10', 'IMIN20', 'IMIN30', 'IMIN60', 'IMXD5', 'IMXD10', 'IMXD20', 'IMXD30', 'IMXD60', 'CORR5', 'CORR10', 'CORR20', 'CORR30', 'CORR60', 'CORD5', 'CORD10', 'CORD20', 'CORD30', 'CORD60', 'CNTP5', 'CNTP10', 'CNTP20', 'CNTP30', 'CNTP60', 'CNTN5', 'CNTN10', 'CNTN20', 'CNTN30', 'CNTN60', 'CNTD5', 'CNTD10', 'CNTD20', 'CNTD30', 'CNTD60', 'SUMP5', 'SUMP10', 'SUMP20', 'SUMP30', 'SUMP60', 'SUMN5', 'SUMN10', 'SUMN20', 'SUMN30', 'SUMN60', 'SUMD5', 'SUMD10', 'SUMD20', 'SUMD30', 'SUMD60', 'VMA5', 'VMA10', 'VMA20', 'VMA30', 'VMA60', 'VSTD5', 'VSTD10', 'VSTD20', 'VSTD30', 'VSTD60', 'WVMA5', 'WVMA10', 'WVMA20', 'WVMA30', 'WVMA60', 'VSUMP5', 'VSUMP10', 'VSUMP20', 'VSUMP30', 'VSUMP60', 'VSUMN5', 'VSUMN10', 'VSUMN20', 'VSUMN30', 'VSUMN60', 'VSUMD5', 'VSUMD10', 'VSUMD20', 'VSUMD30', 'VSUMD60', 'LABEL0']\n",
      "                         LABEL0\n",
      "datetime   instrument          \n",
      "2018-01-02 SH600000    0.000000\n",
      "           SH600010   -0.003984\n",
      "           SH600011   -0.004747\n",
      "           SH600015    0.002190\n",
      "           SH600016   -0.004662\n",
      "...                         ...\n",
      "2021-05-21 SZ002938         NaN\n",
      "           SZ003816         NaN\n",
      "           SZ300015         NaN\n",
      "           SZ300059         NaN\n",
      "           SZ300498         NaN\n",
      "\n",
      "[75796 rows x 1 columns]\n",
      "                           KMID      KLEN     KMID2       KUP      KUP2  \\\n",
      "datetime   instrument                                                     \n",
      "2018-01-02 SH600000    0.008723  0.013481  0.647063  0.003965  0.294118   \n",
      "           SH600010    0.016260  0.024390  0.666667  0.004065  0.166667   \n",
      "           SH600011    0.014563  0.022654  0.642856  0.004854  0.214289   \n",
      "           SH600015    0.009978  0.013304  0.749990  0.002217  0.166670   \n",
      "           SH600016    0.010676  0.018980  0.562501  0.005931  0.312498   \n",
      "...                         ...       ...       ...       ...       ...   \n",
      "2021-05-21 SZ002938   -0.019608  0.027124 -0.722892  0.007516  0.277108   \n",
      "           SZ003816    0.007273  0.010909  0.666667  0.003636  0.333333   \n",
      "           SZ300015    0.021798  0.042441  0.513597  0.005257  0.123867   \n",
      "           SZ300059   -0.036592  0.039665 -0.922536  0.000000  0.000000   \n",
      "           SZ300498   -0.021307  0.023437 -0.909090  0.001421  0.060608   \n",
      "\n",
      "                           KLOW     KLOW2      KSFT     KSFT2     OPEN0  ...  \\\n",
      "datetime   instrument                                                    ...   \n",
      "2018-01-02 SH600000    0.000793  0.058819  0.005551  0.411764  0.991352  ...   \n",
      "           SH600010    0.004065  0.166667  0.016260  0.666667  0.984000  ...   \n",
      "           SH600011    0.003236  0.142856  0.012945  0.571423  0.985646  ...   \n",
      "           SH600015    0.001109  0.083340  0.008869  0.666660  0.990121  ...   \n",
      "           SH600016    0.002373  0.125002  0.007118  0.375005  0.989437  ...   \n",
      "...                         ...       ...       ...       ...       ...  ...   \n",
      "2021-05-21 SZ002938    0.000000  0.000000 -0.027124 -1.000000  1.020000  ...   \n",
      "           SZ003816    0.000000  0.000000  0.003636  0.333333  0.992780  ...   \n",
      "           SZ300015    0.015387  0.362536  0.031927  0.752266  0.978667  ...   \n",
      "           SZ300059    0.003073  0.077464 -0.033520 -0.845071  1.037982  ...   \n",
      "           SZ300498    0.000710  0.030302 -0.022017 -0.939397  1.021771  ...   \n",
      "\n",
      "                         VSUMN5   VSUMN10   VSUMN20   VSUMN30   VSUMN60  \\\n",
      "datetime   instrument                                                     \n",
      "2018-01-02 SH600000    0.386506  0.388162  0.508938  0.531579  0.509718   \n",
      "           SH600010    0.556868  0.456156  0.531977  0.488366  0.494931   \n",
      "           SH600011    0.714064  0.510931  0.554335  0.498614  0.490070   \n",
      "           SH600015    0.431950  0.372585  0.480976  0.524183  0.515839   \n",
      "           SH600016    0.378214  0.376541  0.508622  0.533119  0.503450   \n",
      "...                         ...       ...       ...       ...       ...   \n",
      "2021-05-21 SZ002938    0.617293  0.574350  0.533444  0.524763  0.505060   \n",
      "           SZ003816    0.452107  0.479687  0.475304  0.491207  0.517137   \n",
      "           SZ300015    0.511757  0.545137  0.533500  0.509958  0.510960   \n",
      "           SZ300059    0.951983  0.452985  0.481947  0.477215  0.535657   \n",
      "           SZ300498    0.614665  0.573165  0.491948  0.506782  0.629832   \n",
      "\n",
      "                         VSUMD5   VSUMD10   VSUMD20   VSUMD30   VSUMD60  \n",
      "datetime   instrument                                                    \n",
      "2018-01-02 SH600000    0.226988  0.223677 -0.017876 -0.063158 -0.019435  \n",
      "           SH600010   -0.113736  0.087688 -0.063954  0.023269  0.010138  \n",
      "           SH600011   -0.428129 -0.021863 -0.108671  0.002772  0.019860  \n",
      "           SH600015    0.136099  0.254831  0.038048 -0.048367 -0.031678  \n",
      "           SH600016    0.243573  0.246919 -0.017245 -0.066238 -0.006899  \n",
      "...                         ...       ...       ...       ...       ...  \n",
      "2021-05-21 SZ002938   -0.234585 -0.148699 -0.066888 -0.049526 -0.010120  \n",
      "           SZ003816    0.095787  0.040625  0.049392  0.017587 -0.034274  \n",
      "           SZ300015   -0.023514 -0.090274 -0.067000 -0.019915 -0.021920  \n",
      "           SZ300059   -0.903966  0.094029  0.036105  0.045570 -0.071315  \n",
      "           SZ300498   -0.229329 -0.146330  0.016105 -0.013563 -0.259665  \n",
      "\n",
      "[75796 rows x 158 columns]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import qlib\n",
    "from qlib.config import REG_CN\n",
    "from qlib.contrib.data.handler import Alpha158\n",
    "\n",
    "data_handler_config = {\n",
    "    \"start_time\": \"2018-01-01\",\n",
    "    \"end_time\": \"2021-06-03\",\n",
    "    \"fit_start_time\": \"2019-01-01\",\n",
    "    \"fit_end_time\": \"2020-12-31\",\n",
    "    \"instruments\": \"csi100\",\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    provider_uri = \"~/.qlib/qlib_data/qlib_cn_1d\"  # target_dir\n",
    "    qlib.init(provider_uri=provider_uri, region=REG_CN)\n",
    "    h = Alpha158(**data_handler_config)\n",
    "\n",
    "    # get all the columns of the data\n",
    "    print(h.get_cols())\n",
    "\n",
    "    # fetch all the labels\n",
    "    print(h.fetch(col_set=\"label\"))\n",
    "\n",
    "    # fetch all the features\n",
    "    print(h.fetch(col_set=\"feature\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9175be8-9f77-4b98-9c83-6edd78fa0cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>$close</th>\n",
       "      <th>$volume</th>\n",
       "      <th>Ref($close, 1)</th>\n",
       "      <th>Mean($close, 3)</th>\n",
       "      <th>$high-$low</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instrument</th>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">sz300643</th>\n",
       "      <th>2021-05-28</th>\n",
       "      <td>1.867190</td>\n",
       "      <td>39383888.0</td>\n",
       "      <td>1.811257</td>\n",
       "      <td>1.827159</td>\n",
       "      <td>0.055933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-31</th>\n",
       "      <td>1.880351</td>\n",
       "      <td>30428524.0</td>\n",
       "      <td>1.867190</td>\n",
       "      <td>1.852933</td>\n",
       "      <td>0.047708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-01</th>\n",
       "      <td>1.852384</td>\n",
       "      <td>23077452.0</td>\n",
       "      <td>1.880351</td>\n",
       "      <td>1.866642</td>\n",
       "      <td>0.042773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-02</th>\n",
       "      <td>1.776710</td>\n",
       "      <td>30782904.0</td>\n",
       "      <td>1.852384</td>\n",
       "      <td>1.836482</td>\n",
       "      <td>0.093771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-03</th>\n",
       "      <td>1.778355</td>\n",
       "      <td>15098765.0</td>\n",
       "      <td>1.776710</td>\n",
       "      <td>1.802483</td>\n",
       "      <td>0.024676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         $close     $volume  Ref($close, 1)  Mean($close, 3)  \\\n",
       "instrument datetime                                                            \n",
       "sz300643   2021-05-28  1.867190  39383888.0        1.811257         1.827159   \n",
       "           2021-05-31  1.880351  30428524.0        1.867190         1.852933   \n",
       "           2021-06-01  1.852384  23077452.0        1.880351         1.866642   \n",
       "           2021-06-02  1.776710  30782904.0        1.852384         1.836482   \n",
       "           2021-06-03  1.778355  15098765.0        1.776710         1.802483   \n",
       "\n",
       "                       $high-$low  \n",
       "instrument datetime                \n",
       "sz300643   2021-05-28    0.055933  \n",
       "           2021-05-31    0.047708  \n",
       "           2021-06-01    0.042773  \n",
       "           2021-06-02    0.093771  \n",
       "           2021-06-03    0.024676  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qlib.data import D\n",
    "instruments = ['sz300643']\n",
    "fields = ['$close', '$volume', 'Ref($close, 1)', 'Mean($close, 3)', '$high-$low']\n",
    "D.features(instruments, fields, start_time='2020-01-01', end_time='2021-06-03', freq='day').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a37f0f3-d4d2-4dfa-bc39-d57b2d58fb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = h.fetch(col_set=[\"feature\",\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b90793a-adf2-4302-88f1-0c8037a8cb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\n",
    "from sklearn.utils.validation import _deprecate_positional_args\n",
    "\n",
    "\n",
    "# modified code for group gaps; source\n",
    "# https://github.com/getgaurav2/scikit-learn/blob/d4a3af5cc9da3a76f0266932644b884c99724c57/sklearn/model_selection/_split.py#L2243\n",
    "class PurgedGroupTimeSeriesSplit(_BaseKFold):\n",
    "    \"\"\"Time Series cross-validator variant with non-overlapping groups.\n",
    "    Allows for a gap in groups to avoid potentially leaking info from\n",
    "    train into test if the model has windowed or lag features.\n",
    "    Provides train/test indices to split time series data samples\n",
    "    that are observed at fixed time intervals according to a\n",
    "    third-party provided group.\n",
    "    In each split, test indices must be higher than before, and thus shuffling\n",
    "    in cross validator is inappropriate.\n",
    "    This cross-validation object is a variation of :class:`KFold`.\n",
    "    In the kth split, it returns first k folds as train set and the\n",
    "    (k+1)th fold as test set.\n",
    "    The same group will not appear in two different folds (the number of\n",
    "    distinct groups has to be at least equal to the number of folds).\n",
    "    Note that unlike standard cross-validation methods, successive\n",
    "    training sets are supersets of those that come before them.\n",
    "    Read more in the :ref:`User Guide <cross_validation>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=5\n",
    "        Number of splits. Must be at least 2.\n",
    "    max_train_group_size : int, default=Inf\n",
    "        Maximum group size for a single training set.\n",
    "    group_gap : int, default=None\n",
    "        Gap between train and test\n",
    "    max_test_group_size : int, default=Inf\n",
    "        We discard this number of groups from the end of each train split\n",
    "    \"\"\"\n",
    "\n",
    "    @_deprecate_positional_args\n",
    "    def __init__(self,\n",
    "                 n_splits=5,\n",
    "                 *,\n",
    "                 max_train_group_size=np.inf,\n",
    "                 max_test_group_size=np.inf,\n",
    "                 group_gap=None,\n",
    "                 verbose=False\n",
    "                 ):\n",
    "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
    "        self.max_train_group_size = max_train_group_size\n",
    "        self.group_gap = group_gap\n",
    "        self.max_test_group_size = max_test_group_size\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        groups : array-like of shape (n_samples,)\n",
    "            Group labels for the samples used while splitting the dataset into\n",
    "            train/test set.\n",
    "        Yields\n",
    "        ------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        \"\"\"\n",
    "        if groups is None:\n",
    "            raise ValueError(\n",
    "                \"The 'groups' parameter should not be None\")\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        n_samples = _num_samples(X)\n",
    "        n_splits = self.n_splits\n",
    "        group_gap = self.group_gap\n",
    "        max_test_group_size = self.max_test_group_size\n",
    "        max_train_group_size = self.max_train_group_size\n",
    "        n_folds = n_splits + 1\n",
    "        group_dict = {}\n",
    "        u, ind = np.unique(groups, return_index=True)\n",
    "        unique_groups = u[np.argsort(ind)]\n",
    "        n_samples = _num_samples(X)\n",
    "        n_groups = _num_samples(unique_groups)\n",
    "        for idx in np.arange(n_samples):\n",
    "            if (groups[idx] in group_dict):\n",
    "                group_dict[groups[idx]].append(idx)\n",
    "            else:\n",
    "                group_dict[groups[idx]] = [idx]\n",
    "        if n_folds > n_groups:\n",
    "            raise ValueError(\n",
    "                (\"Cannot have number of folds={0} greater than\"\n",
    "                 \" the number of groups={1}\").format(n_folds,\n",
    "                                                     n_groups))\n",
    "\n",
    "        group_test_size = min(n_groups // n_folds, max_test_group_size)\n",
    "        group_test_starts = range(n_groups - n_splits * group_test_size,\n",
    "                                  n_groups, group_test_size)\n",
    "        for group_test_start in group_test_starts:\n",
    "            train_array = []\n",
    "            test_array = []\n",
    "\n",
    "            group_st = max(0, group_test_start - group_gap - max_train_group_size)\n",
    "            for train_group_idx in unique_groups[group_st:(group_test_start - group_gap)]:\n",
    "                train_array_tmp = group_dict[train_group_idx]\n",
    "\n",
    "                train_array = np.sort(np.unique(\n",
    "                    np.concatenate((train_array,\n",
    "                                    train_array_tmp)),\n",
    "                    axis=None), axis=None)\n",
    "\n",
    "            train_end = train_array.size\n",
    "\n",
    "            for test_group_idx in unique_groups[group_test_start:\n",
    "                    group_test_start +\n",
    "                    group_test_size]:\n",
    "                test_array_tmp = group_dict[test_group_idx]\n",
    "                test_array = np.sort(np.unique(\n",
    "                    np.concatenate((test_array,\n",
    "                                    test_array_tmp)),\n",
    "                    axis=None), axis=None)\n",
    "\n",
    "            test_array = test_array[group_gap:]\n",
    "\n",
    "            if self.verbose > 0:\n",
    "                pass\n",
    "\n",
    "            yield [int(i) for i in train_array], [int(i) for i in test_array]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "500ab4dd-7d04-4c3f-bf63-071e392c5a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from typing import Text, Union\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def create_ae_mlp(num_columns, num_labels, hidden_units, dropout_rates, ls=1e-2, lr=1e-3):\n",
    "    inp = tf.keras.layers.Input(shape=(num_columns,))\n",
    "    x0 = tf.keras.layers.BatchNormalization()(inp)\n",
    "\n",
    "    encoder = tf.keras.layers.GaussianNoise(dropout_rates[0])(x0)\n",
    "    encoder = tf.keras.layers.Dense(hidden_units[0])(encoder)\n",
    "    encoder = tf.keras.layers.BatchNormalization()(encoder)\n",
    "    encoder = tf.keras.layers.Activation('swish')(encoder)\n",
    "\n",
    "    decoder = tf.keras.layers.Dropout(dropout_rates[1])(encoder)\n",
    "    decoder = tf.keras.layers.Dense(num_columns, name='decoder')(decoder)\n",
    "\n",
    "    x_ae = tf.keras.layers.Dense(hidden_units[1])(decoder)\n",
    "    x_ae = tf.keras.layers.BatchNormalization()(x_ae)\n",
    "    x_ae = tf.keras.layers.Activation('swish')(x_ae)\n",
    "    x_ae = tf.keras.layers.Dropout(dropout_rates[2])(x_ae)\n",
    "\n",
    "    out_ae = tf.keras.layers.Dense(num_labels, activation='linear', name='ae_action')(x_ae)\n",
    "\n",
    "    x = tf.keras.layers.Concatenate()([x0, encoder])\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rates[3])(x)\n",
    "\n",
    "    for i in range(2, len(hidden_units)):\n",
    "        x = tf.keras.layers.Dense(hidden_units[i])(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation('swish')(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rates[i + 2])(x)\n",
    "\n",
    "    out = tf.keras.layers.Dense(num_labels, activation='linear', name='action')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=[decoder, out_ae, out])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                  loss={'decoder': tf.keras.losses.MeanSquaredError(),\n",
    "                        'ae_action': tf.keras.losses.MeanSquaredError(),\n",
    "                        'action': tf.keras.losses.MeanSquaredError(),\n",
    "                        },\n",
    "                  metrics={'decoder': tf.keras.metrics.MeanAbsoluteError(name='mae'),\n",
    "                           'ae_action': tf.keras.metrics.MeanAbsoluteError(name='mae'),\n",
    "                           'action': tf.keras.metrics.MeanAbsoluteError(name='mae'),\n",
    "                           },\n",
    "                  )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56e00007-4823-488d-b87c-102f497a5cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 6s 723ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 2s 561ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 2s 619ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 2s 557ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 2s 562ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 2s 581ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 2s 614ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 3s 622ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 3s 602ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 2s 607ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 1/10\n",
      "7/7 [==============================] - 9s 791ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 5s 647ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 5s 675ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 5s 654ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 4s 604ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 4s 592ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 4s 599ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 4s 586ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 4s 597ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 4s 588ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 10s 717ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 6s 644ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 7s 652ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 6s 618ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 6s 604ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 6s 602ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 6s 600ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 6s 601ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 6s 602ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 6s 598ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 11s 654ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 8s 608ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 8s 611ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 8s 613ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 8s 611ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 8s 609ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 8s 608ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 8s 606ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 8s 607ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 8s 610ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 1/10\n",
      "16/16 [==============================] - 13s 644ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 10s 616ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 10s 624ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 11s 673ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 11s 667ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 11s 685ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 10s 641ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 10s 606ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 10s 616ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 10s 605ms/step - loss: nan - decoder_loss: nan - ae_action_loss: nan - action_loss: nan - decoder_mae: nan - ae_action_mae: nan - action_mae: nan - val_loss: nan - val_decoder_loss: nan - val_ae_action_loss: nan - val_action_loss: nan - val_decoder_mae: nan - val_ae_action_mae: nan - val_action_mae: nan\n"
     ]
    }
   ],
   "source": [
    "X, y = data[\"feature\"].values, data[\"label\"].values\n",
    "num_columns = X.shape[1]\n",
    "num_labels = 1\n",
    "params = {'num_columns': num_columns,\n",
    "          'num_labels': num_labels,\n",
    "          'hidden_units': [96, 96, 896, 448, 448, 256],\n",
    "          'dropout_rates': [0.03527936123679956, 0.038424974585075086, 0.42409238408801436, 0.10431484318345882,\n",
    "                            0.49230389137187497, 0.32024444956111164, 0.2716856145683449, 0.4379233941604448],\n",
    "          'ls': 0,\n",
    "          'lr': 1e-3,\n",
    "          }\n",
    "group_index = data[\"feature\"].index.get_level_values('datetime').astype(str)\n",
    "gkf = PurgedGroupTimeSeriesSplit(n_splits=5, group_gap=2)\n",
    "for fold, (tr, te) in enumerate(gkf.split(X, y, group_index)):\n",
    "    model = create_ae_mlp(**params)\n",
    "    es = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=2, mode='max',\n",
    "                       baseline=None, restore_best_weights=True, verbose=1)\n",
    "    model.fit(X[tr], [X[tr], y[tr], y[tr]],\n",
    "              validation_data=(X[te], [X[te], y[te], y[te]]), epochs=10,\n",
    "              batch_size=4096, verbose=1)\n",
    "    model.save(f'model_{fold}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf2cd685-f81a-4c95-bf67-0b286ded2c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_tag(*args, **kwargs):\n",
    "    params = {}\n",
    "    params.update(kwargs)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7fdada3-f79f-4680-a0ae-6bca9bf3d3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 'b'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_tag(**{'a':'b'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "327c263a-5c74-43b3-90a2-5f65c9f6d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "def scanf_tasks(config_root_path):\n",
    "    tasks = []\n",
    "    for file in os.listdir(config_root_path):\n",
    "        if not file.endswith(\".yaml\"):\n",
    "                continue\n",
    "        with open(os.path.join(config_root_path, file)) as fp:\n",
    "            config = yaml.safe_load(fp)\n",
    "            tasks.append(config.get(\"task\"))\n",
    "\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "35f209c7-b63f-4e2c-b5a1-b3b25daa7115",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_root_path = \"/Users/harry/Workspace/qlib/examples/benchmarks/MLP\"\n",
    "tasks = scanf_tasks(config_root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e25b8a99-60e1-4260-91c0-6cc27ddc32e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': {'class': 'GRU',\n",
       "  'module_path': 'qlib.contrib.model.pytorch_gru_ts',\n",
       "  'kwargs': {'d_feat': 20,\n",
       "   'hidden_size': 64,\n",
       "   'num_layers': 2,\n",
       "   'dropout': 0.0,\n",
       "   'n_epochs': 200,\n",
       "   'lr': '2e-4',\n",
       "   'early_stop': 10,\n",
       "   'batch_size': 800,\n",
       "   'metric': 'loss',\n",
       "   'loss': 'mse',\n",
       "   'n_jobs': 20,\n",
       "   'GPU': 0}},\n",
       " 'dataset': {'class': 'TSDatasetH',\n",
       "  'module_path': 'qlib.data.dataset',\n",
       "  'kwargs': {'handler': {'class': 'Alpha158',\n",
       "    'module_path': 'qlib.contrib.data.handler',\n",
       "    'kwargs': {'start_time': datetime.date(2014, 6, 1),\n",
       "     'end_time': datetime.date(2021, 6, 3),\n",
       "     'fit_start_time': datetime.date(2014, 6, 1),\n",
       "     'fit_end_time': datetime.date(2020, 12, 31),\n",
       "     'instruments': 'csi300',\n",
       "     'infer_processors': [{'class': 'FilterCol',\n",
       "       'kwargs': {'fields_group': 'feature',\n",
       "        'col_list': ['RESI5',\n",
       "         'WVMA5',\n",
       "         'RSQR5',\n",
       "         'KLEN',\n",
       "         'RSQR10',\n",
       "         'CORR5',\n",
       "         'CORD5',\n",
       "         'CORR10',\n",
       "         'ROC60',\n",
       "         'RESI10',\n",
       "         'VSTD5',\n",
       "         'RSQR60',\n",
       "         'CORR60',\n",
       "         'WVMA60',\n",
       "         'STD5',\n",
       "         'RSQR20',\n",
       "         'CORD60',\n",
       "         'CORD10',\n",
       "         'CORR20',\n",
       "         'KLOW']}},\n",
       "      {'class': 'RobustZScoreNorm',\n",
       "       'kwargs': {'fields_group': 'feature', 'clip_outlier': True}},\n",
       "      {'class': 'Fillna', 'kwargs': {'fields_group': 'feature'}}],\n",
       "     'learn_processors': [{'class': 'DropnaLabel'},\n",
       "      {'class': 'CSRankNorm', 'kwargs': {'fields_group': 'label'}}],\n",
       "     'label': ['Ref($close, -2) / Ref($close, -1) - 1']}},\n",
       "   'segments': {'train': [datetime.date(2014, 6, 1),\n",
       "     datetime.date(2019, 1, 1)],\n",
       "    'valid': [datetime.date(2019, 1, 2), datetime.date(2021, 1, 1)],\n",
       "    'test': [datetime.date(2021, 1, 2), datetime.date(2021, 6, 3)]},\n",
       "   'step_len': 20}},\n",
       " 'record': [{'class': 'SignalRecord',\n",
       "   'module_path': 'qlib.workflow.record_temp',\n",
       "   'kwargs': {}},\n",
       "  {'class': 'SigAnaRecord',\n",
       "   'module_path': 'qlib.workflow.record_temp',\n",
       "   'kwargs': {'ana_long_short': False, 'ann_scaler': 252}},\n",
       "  {'class': 'PortAnaRecord',\n",
       "   'module_path': 'qlib.workflow.record_temp',\n",
       "   'kwargs': {'config': {'strategy': {'class': 'TopkDropoutStrategy',\n",
       "      'module_path': 'qlib.contrib.strategy.strategy',\n",
       "      'kwargs': {'topk': 50, 'n_drop': 5}},\n",
       "     'backtest': {'verbose': False,\n",
       "      'limit_threshold': 0.095,\n",
       "      'account': 100000000,\n",
       "      'benchmark': 'SH000300',\n",
       "      'deal_price': 'close',\n",
       "      'open_cost': 0.0015,\n",
       "      'close_cost': 0.0025,\n",
       "      'min_cost': 5}}}}]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81405f50-d261-47ad-a7fb-02c8b5629323",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
